

```{r}
install.packages("nnet")
```

```{r, include=FALSE}
library(tidyverse)
library(tidymodels)
library(caret)
library(mice)
library(VIM)
library(ranger)
library(RColorBrewer)
library(rpart)
library(rattle)
library(e1071)
library(xgboost)
library(usemodels)
library(nnet)
library(caret)
install.packages("varImp")
library("varImp")
```

```{r}
student <- read.csv("ames_student.csv")
competition <- read_csv("ames_competition.csv")

```

```{r}
student <- student %>% mutate_if(is.character,as_factor)

```

```{r}
student1 <- student %>% select(c("Gr_Liv_Area","Year_Built","Full_Bath",
                                 "Garage_Area","Garage_Cars",
                                 "Total_Bsmt_SF","First_Flr_SF",
                                 "Year_Remod_Add",
                                 "Second_Flr_SF","Above_Median"))

```

```{r}
set.seed(123)
student1_split = initial_split(student1, prop = 0.7, strata = Above_Median)
train1 = training(student1_split)
test1 = testing(student1_split)

```

```{r}
set.seed(123)
folds = vfold_cv(train1, v = 5)

```

```{r}
start_time = Sys.time() #for timing

neural_grid = grid_regular(
  hidden_units(range = c(1,2)),
  penalty(range = c(-10,-1)), 
  epochs(range = c(1,100)),
  levels = 10)
  
neural_recipe = recipe(Above_Median ~., train1) %>%
  step_normalize(all_predictors(), -all_nominal())

neural_model = 
  mlp(hidden_units = tune(), penalty = tune(), 
      epochs = tune()) %>%
  set_mode("classification") %>% 
  set_engine("nnet", verbose = 0) 
  
neural_workflow <- 
  workflow() %>% 
  add_recipe(neural_recipe) %>% 
  add_model(neural_model) 

set.seed(1234)
neural_tune <-
  tune_grid(neural_workflow, resamples = folds, grid = neural_grid)

end_time = Sys.time()
end_time-start_time
```

```{r}
neural_tune %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, hidden_units, penalty, epochs) %>%
  pivot_longer(hidden_units:epochs,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "Accuracy")
```

```{r}
best_nn = select_best(neural_tune, "accuracy")

final_nn = finalize_workflow(
  neural_workflow,
  best_nn)

final_nn
```

```{r}
final_nn_fit = fit(final_nn, train1)
```

```{r}
trainprednn = predict(final_nn_fit, train1)
head(trainprednn)
```

```{r}
confusionMatrix(trainprednn$.pred_class, train1$Above_Median, 
                positive = "Yes")
```
```{r}
varImp(neural_model)
```


